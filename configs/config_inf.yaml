defaults:
  - _self_
  - /algo: bd3lm
  - /model: small
  - /noise: loglinear

mode: sample_eval  # train / sample_eval
diffusion: absorbing_state

seed: 42

block_size: 64

data:
  dataset_root: /mnt/e/1Master1/0Science_Research/0DLM-SSCC/Dataset
  test_dataset: DIV2K
  image_size_test: 256
  num_images_test: 1
  is_channel_wised: True  # RGB False; Gray True
  patch_size: ${sqrt:${block_size}}
  num_patches_test: ${compute_num_patches:${data.num_images_test},${data.image_size_test},${data.patch_size}}
  tokenizer_name_or_path: /mnt/e/1Master1/0Science_Research/0DLM-SSCC/Model/gpt2
  ac_coder_base: 2
  ac_coder_precision: 32

loader:
  eval_batch_size: 1
  
sampling:
  checkpoint_path: /mnt/e/1Master1/0Science_Research/0DLM-SSCC/Model/bd3lm/bd3lm-owt-block_size${block_size}/best.ckpt
  noise_removal: False
  num_sample_batches: -1  # Total samples: `num_gpus` * `loader.eval_batch_size` * num_sample_batches
  var_length: False
  logdir: ./samples_${algo.name}_len${model.length}_blocksize${block_size}
  nucleus_p: 1
  first_hitting: True # should be set to true when T >> block_size
  kv_cache: True
  reset_channel_context: False

hydra:
  run:
    dir: ./outputs/test/${data.test_dataset}/${now:%Y.%m.%d.%H%M}
  job:
    chdir: true